{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_variation_1month.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vO2IO7bRLpZ",
        "colab_type": "code",
        "outputId": "a624f342-9d9b-4797-dfba-1bfd795e9d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Model\n",
        "from keras.layers import Input,Dense,LSTM,GRU,BatchNormalization,Dropout,concatenate\n",
        "from keras.models import Sequential\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXXXy0CzRy57",
        "colab_type": "code",
        "outputId": "742d6524-274d-4ea6-dc78-8cbfa2141600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_data = pd.read_csv('/gdrive/My Drive/Colab Notebooks/thesis_anirban/X_train_new1.csv')\n",
        "Y_data = pd.read_csv('/gdrive/My Drive/Colab Notebooks/thesis_anirban/Y_train_new1.csv')\n",
        "X_data.drop([X_data.columns[0]],axis = 1,inplace = True)\n",
        "Y_data.drop([Y_data.columns[0]],axis = 1,inplace = True)\n",
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(366760, 18)\n",
            "(366760, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYlMBBrJSFtU",
        "colab_type": "text"
      },
      "source": [
        "**1 month training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwEJtZtMSAu9",
        "colab_type": "code",
        "outputId": "f9e4b19c-c998-4ed8-fb8e-96711befbe21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train_1 = pd.DataFrame()\n",
        "X_test_1 = pd.DataFrame()\n",
        "Y_train_1 = pd.DataFrame()\n",
        "Y_test_1 = pd.DataFrame()\n",
        "for i in range(0,40) :\n",
        "  X_train_1 = X_train_1.append(X_data.iloc[9169*i : (9169*i) + 4454,:])\n",
        "  X_test_1 = X_test_1.append(X_data.iloc[9169*i + 4454 : 9169*i + 4954,:])\n",
        "  Y_train_1 = Y_train_1.append(Y_data.iloc[9169*i : (9169*i) + 4454,:])\n",
        "  Y_test_1 = Y_test_1.append(Y_data.iloc[9169*i + 4454 : 9169*i + 4954,:])\n",
        "print(X_train_1.shape)\n",
        "print(Y_train_1.shape)\n",
        "print(X_test_1.shape)\n",
        "print(Y_test_1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(178160, 18)\n",
            "(178160, 1)\n",
            "(20000, 18)\n",
            "(20000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okFvhnKhTfaG",
        "colab_type": "text"
      },
      "source": [
        "Random  Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jUrJ8QTe8Y",
        "colab_type": "code",
        "outputId": "c759c3c4-d8fe-4556-f0f7-fba3bc2ed805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_train_rf = X_train_1.drop([X_train_1.columns[0],X_train_1.columns[1],X_train_1.columns[2],X_train_1.columns[3],X_train_1.columns[4],X_train_1.columns[10],X_train_1.columns[11],X_train_1.columns[12],X_train_1.columns[13]],axis = 1)\n",
        "X_train_rf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ft_5</th>\n",
              "      <th>ft_4</th>\n",
              "      <th>ft_3</th>\n",
              "      <th>ft_2</th>\n",
              "      <th>ft_1</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>weekday</th>\n",
              "      <th>exp_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>135</td>\n",
              "      <td>129</td>\n",
              "      <td>150</td>\n",
              "      <td>164</td>\n",
              "      <td>152</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>4</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129</td>\n",
              "      <td>150</td>\n",
              "      <td>164</td>\n",
              "      <td>152</td>\n",
              "      <td>131</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150</td>\n",
              "      <td>164</td>\n",
              "      <td>152</td>\n",
              "      <td>131</td>\n",
              "      <td>138</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>164</td>\n",
              "      <td>152</td>\n",
              "      <td>131</td>\n",
              "      <td>138</td>\n",
              "      <td>147</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>4</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>152</td>\n",
              "      <td>131</td>\n",
              "      <td>138</td>\n",
              "      <td>147</td>\n",
              "      <td>127</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>4</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ft_5  ft_4  ft_3  ft_2  ft_1        lat        lon  weekday  exp_avg\n",
              "0   135   129   150   164   152  40.776228 -73.982119        4      153\n",
              "1   129   150   164   152   131  40.776228 -73.982119        4      137\n",
              "2   150   164   152   131   138  40.776228 -73.982119        4      137\n",
              "3   164   152   131   138   147  40.776228 -73.982119        4      144\n",
              "4   152   131   138   147   127  40.776228 -73.982119        4      132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVCgVGe3T4L2",
        "colab_type": "code",
        "outputId": "ffe3d672-6342-4b25-9ee1-a8b43c8068d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X_test_rf = X_test_1.drop([X_test_1.columns[0],X_test_1.columns[1],X_test_1.columns[2],X_test_1.columns[3],X_test_1.columns[4],X_test_1.columns[10],X_test_1.columns[11],X_test_1.columns[12],X_test_1.columns[13]],axis = 1)\n",
        "X_test_rf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ft_5</th>\n",
              "      <th>ft_4</th>\n",
              "      <th>ft_3</th>\n",
              "      <th>ft_2</th>\n",
              "      <th>ft_1</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>weekday</th>\n",
              "      <th>exp_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4454</th>\n",
              "      <td>36</td>\n",
              "      <td>33</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4455</th>\n",
              "      <td>33</td>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4456</th>\n",
              "      <td>42</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4457</th>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>20</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4458</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>40.776228</td>\n",
              "      <td>-73.982119</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ft_5  ft_4  ft_3  ft_2  ft_1        lat        lon  weekday  exp_avg\n",
              "4454    36    33    42    28    20  40.776228 -73.982119        0       23\n",
              "4455    33    42    28    20     0  40.776228 -73.982119        0        6\n",
              "4456    42    28    20     0    26  40.776228 -73.982119        0       20\n",
              "4457    28    20     0    26    20  40.776228 -73.982119        0       20\n",
              "4458    20     0    26    20    19  40.776228 -73.982119        0       19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C5V7i40UJqA",
        "colab_type": "code",
        "outputId": "3cb7f4ed-11c4-45f3-e9e2-b656bf442996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "regr1 = RandomForestRegressor(max_features='sqrt',min_samples_leaf=4,min_samples_split=3,n_estimators=40, n_jobs=-1)\n",
        "regr1.fit(X_train_rf, Y_train_1)\n",
        "y_pred = regr1.predict(X_test_rf)\n",
        "rndf_test_predictions = [round(value) for value in y_pred]\n",
        "y_pred = regr1.predict(X_train_rf)\n",
        "rndf_train_predictions = [round(value) for value in y_pred]\n",
        "Y_train_arr = np.array(Y_train_1)\n",
        "Y_test_arr = np.array(Y_test_1)\n",
        "print(\"Train MAE = \", mean_absolute_error(Y_train_1,rndf_train_predictions))\n",
        "print(\"Train MAPE = \",(mean_absolute_error(Y_train_1,rndf_train_predictions)/((sum(Y_train_arr))/len(Y_train_arr))))\n",
        "print(\"Test MAE = \", mean_absolute_error(Y_test_1,rndf_test_predictions))\n",
        "print(\"Test MAPE = \",(mean_absolute_error(Y_test_1,rndf_test_predictions)/((sum(Y_test_arr))/len(Y_test_arr))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train MAE =  5.480141445891333\n",
            "Train MAPE =  [0.0923676]\n",
            "Test MAE =  8.491\n",
            "Test MAPE =  [0.13966908]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSj-7vjcUhUH",
        "colab_type": "text"
      },
      "source": [
        "ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2rHB5DnUfqg",
        "colab_type": "code",
        "outputId": "01677022-9d70-455f-c32e-504b93bac3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17368
        }
      },
      "source": [
        "input_shape = (X_train_1.shape[1],)\n",
        "input_case = Input(shape = input_shape)\n",
        "tower = Dense(1024, activation = 'relu', kernel_initializer = 'he_normal')(input_case)\n",
        "tower = BatchNormalization()(tower)\n",
        "tower = Dropout(0.5)(tower)\n",
        "tower = Dense(1024, activation = 'relu', kernel_initializer = 'he_normal')(tower)\n",
        "tower = BatchNormalization()(tower)\n",
        "tower = Dropout(0.5)(tower)\n",
        "tower = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(tower)\n",
        "\n",
        "#block 1\n",
        "tower1 = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(tower)\n",
        "tower1 = BatchNormalization()(tower1)\n",
        "tower1 = Dropout(0.5)(tower1)\n",
        "tower1 = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(tower1)\n",
        "tower1 = BatchNormalization()(tower1)\n",
        "tower1 = Dropout(0.5)(tower1)\n",
        "\n",
        "#block 2\n",
        "tower2 = Dense(1024, activation = 'relu', kernel_initializer = 'he_normal')(tower)\n",
        "tower2 = BatchNormalization()(tower2)\n",
        "tower2 = Dropout(0.5)(tower2)\n",
        "\n",
        "#block 3\n",
        "tower3 = Dense(1024, activation = 'relu', kernel_initializer = 'he_normal')(tower)\n",
        "tower3 = BatchNormalization()(tower3)\n",
        "tower3 = Dropout(0.5)(tower3)\n",
        "tower3 = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(tower3)\n",
        "tower3 = BatchNormalization()(tower3)\n",
        "tower3 = Dropout(0.5)(tower3)\n",
        "\n",
        "out = concatenate([tower1,tower2,tower3], axis = 1)\n",
        "out = Dense(1024,activation = 'relu',kernel_initializer = 'he_normal')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dropout(0.5)(out)\n",
        "out = Dense(1024,activation = 'relu',kernel_initializer = 'he_normal')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dropout(0.5)(out)\n",
        "out = Dense(512,activation = 'relu',kernel_initializer = 'he_normal')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = Dense(1024)(out)\n",
        "out = Dense(1)(out)\n",
        "\n",
        "model = Model(input_case,out)\n",
        "model.compile(loss = 'logcosh',optimizer = 'adamax', metrics = ['mae'])\n",
        "history = model.fit(X_train_1,Y_train_1,verbose = 1,epochs = 500,batch_size = 1000,validation_data = (X_test_1,Y_test_1))\n",
        "\n",
        "#error calculation\n",
        "test_mae = min(history.history['val_mean_absolute_error'])\n",
        "train_mae = min(history.history['mean_absolute_error'])\n",
        "print(\"Train MAE = \",train_mae)\n",
        "print(\"Train MAPE = \",(train_mae/((sum(Y_train_arr))/len(Y_train_arr))))\n",
        "print(\"Test MAE = \",test_mae)\n",
        "print(\"Test MAPE = \",(test_mae/((sum(Y_test_arr))/len(Y_test_arr))))\n",
        "\n",
        "#plot\n",
        "plt.plot(history.history['mean_absolute_error'],color = 'red')\n",
        "plt.plot(history.history['val_mean_absolute_error'],color = 'blue')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train loss','test loss'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 178160 samples, validate on 20000 samples\n",
            "Epoch 1/500\n",
            "178160/178160 [==============================] - 15s 82us/step - loss: 36.7581 - mean_absolute_error: 37.4386 - val_loss: 41.0532 - val_mean_absolute_error: 41.7386\n",
            "Epoch 2/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 15.4805 - mean_absolute_error: 16.1464 - val_loss: 28.0368 - val_mean_absolute_error: 28.7203\n",
            "Epoch 3/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 12.0224 - mean_absolute_error: 12.6823 - val_loss: 22.1809 - val_mean_absolute_error: 22.8548\n",
            "Epoch 4/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 11.1178 - mean_absolute_error: 11.7750 - val_loss: 16.4477 - val_mean_absolute_error: 17.1249\n",
            "Epoch 5/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 10.5639 - mean_absolute_error: 11.2198 - val_loss: 12.7153 - val_mean_absolute_error: 13.3883\n",
            "Epoch 6/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 10.2757 - mean_absolute_error: 10.9296 - val_loss: 11.9883 - val_mean_absolute_error: 12.6499\n",
            "Epoch 7/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 10.0492 - mean_absolute_error: 10.7020 - val_loss: 11.9404 - val_mean_absolute_error: 12.6053\n",
            "Epoch 8/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.9368 - mean_absolute_error: 10.5888 - val_loss: 9.9011 - val_mean_absolute_error: 10.5390\n",
            "Epoch 9/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.7215 - mean_absolute_error: 10.3727 - val_loss: 10.0530 - val_mean_absolute_error: 10.6843\n",
            "Epoch 10/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.6613 - mean_absolute_error: 10.3115 - val_loss: 10.3379 - val_mean_absolute_error: 11.0046\n",
            "Epoch 11/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.6100 - mean_absolute_error: 10.2609 - val_loss: 11.0858 - val_mean_absolute_error: 11.7335\n",
            "Epoch 12/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.4920 - mean_absolute_error: 10.1412 - val_loss: 10.0957 - val_mean_absolute_error: 10.7524\n",
            "Epoch 13/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.3739 - mean_absolute_error: 10.0225 - val_loss: 9.4619 - val_mean_absolute_error: 10.1115\n",
            "Epoch 14/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.1935 - mean_absolute_error: 9.8401 - val_loss: 9.7698 - val_mean_absolute_error: 10.4258\n",
            "Epoch 15/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.1944 - mean_absolute_error: 9.8422 - val_loss: 8.9640 - val_mean_absolute_error: 9.6095\n",
            "Epoch 16/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.0719 - mean_absolute_error: 9.7186 - val_loss: 9.6251 - val_mean_absolute_error: 10.2811\n",
            "Epoch 17/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.0455 - mean_absolute_error: 9.6914 - val_loss: 9.6606 - val_mean_absolute_error: 10.3226\n",
            "Epoch 18/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 9.0008 - mean_absolute_error: 9.6467 - val_loss: 9.1034 - val_mean_absolute_error: 9.7356\n",
            "Epoch 19/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.8985 - mean_absolute_error: 9.5441 - val_loss: 10.7257 - val_mean_absolute_error: 11.3823\n",
            "Epoch 20/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.9504 - mean_absolute_error: 9.5964 - val_loss: 10.5945 - val_mean_absolute_error: 11.2223\n",
            "Epoch 21/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.9419 - mean_absolute_error: 9.5874 - val_loss: 9.5999 - val_mean_absolute_error: 10.2507\n",
            "Epoch 22/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 8.8521 - mean_absolute_error: 9.4962 - val_loss: 10.5791 - val_mean_absolute_error: 11.2370\n",
            "Epoch 23/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.7815 - mean_absolute_error: 9.4250 - val_loss: 9.9159 - val_mean_absolute_error: 10.5347\n",
            "Epoch 24/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.8311 - mean_absolute_error: 9.4760 - val_loss: 9.5773 - val_mean_absolute_error: 10.2046\n",
            "Epoch 25/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.6564 - mean_absolute_error: 9.2982 - val_loss: 9.8686 - val_mean_absolute_error: 10.5177\n",
            "Epoch 26/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.7006 - mean_absolute_error: 9.3436 - val_loss: 9.0874 - val_mean_absolute_error: 9.7095\n",
            "Epoch 27/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.6928 - mean_absolute_error: 9.3362 - val_loss: 8.9846 - val_mean_absolute_error: 9.6302\n",
            "Epoch 28/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.6482 - mean_absolute_error: 9.2908 - val_loss: 10.3284 - val_mean_absolute_error: 10.9912\n",
            "Epoch 29/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.6704 - mean_absolute_error: 9.3143 - val_loss: 9.4488 - val_mean_absolute_error: 10.0808\n",
            "Epoch 30/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.5397 - mean_absolute_error: 9.1810 - val_loss: 9.9741 - val_mean_absolute_error: 10.5917\n",
            "Epoch 31/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.5411 - mean_absolute_error: 9.1826 - val_loss: 10.3928 - val_mean_absolute_error: 11.0466\n",
            "Epoch 32/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.5915 - mean_absolute_error: 9.2347 - val_loss: 8.9323 - val_mean_absolute_error: 9.5594\n",
            "Epoch 33/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.5080 - mean_absolute_error: 9.1500 - val_loss: 9.2066 - val_mean_absolute_error: 9.8282\n",
            "Epoch 34/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.4687 - mean_absolute_error: 9.1106 - val_loss: 9.8721 - val_mean_absolute_error: 10.5232\n",
            "Epoch 35/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.4368 - mean_absolute_error: 9.0778 - val_loss: 8.9153 - val_mean_absolute_error: 9.5433\n",
            "Epoch 36/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.3662 - mean_absolute_error: 9.0066 - val_loss: 9.2165 - val_mean_absolute_error: 9.8479\n",
            "Epoch 37/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.4004 - mean_absolute_error: 9.0418 - val_loss: 9.0381 - val_mean_absolute_error: 9.6719\n",
            "Epoch 38/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.3483 - mean_absolute_error: 8.9882 - val_loss: 8.7272 - val_mean_absolute_error: 9.3464\n",
            "Epoch 39/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.2975 - mean_absolute_error: 8.9363 - val_loss: 11.0223 - val_mean_absolute_error: 11.6616\n",
            "Epoch 40/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.3678 - mean_absolute_error: 9.0090 - val_loss: 11.3081 - val_mean_absolute_error: 11.9473\n",
            "Epoch 41/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.3283 - mean_absolute_error: 8.9681 - val_loss: 9.2481 - val_mean_absolute_error: 9.8984\n",
            "Epoch 42/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.3143 - mean_absolute_error: 8.9538 - val_loss: 9.6590 - val_mean_absolute_error: 10.3066\n",
            "Epoch 43/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.3417 - mean_absolute_error: 8.9809 - val_loss: 9.1463 - val_mean_absolute_error: 9.7931\n",
            "Epoch 44/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.3260 - mean_absolute_error: 8.9650 - val_loss: 9.4738 - val_mean_absolute_error: 10.1310\n",
            "Epoch 45/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.3653 - mean_absolute_error: 9.0052 - val_loss: 9.2413 - val_mean_absolute_error: 9.8715\n",
            "Epoch 46/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.2621 - mean_absolute_error: 8.9009 - val_loss: 10.2021 - val_mean_absolute_error: 10.8551\n",
            "Epoch 47/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.1533 - mean_absolute_error: 8.7905 - val_loss: 9.3294 - val_mean_absolute_error: 9.9729\n",
            "Epoch 48/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.2291 - mean_absolute_error: 8.8668 - val_loss: 10.2883 - val_mean_absolute_error: 10.9461\n",
            "Epoch 49/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.2281 - mean_absolute_error: 8.8674 - val_loss: 10.9226 - val_mean_absolute_error: 11.5576\n",
            "Epoch 50/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1678 - mean_absolute_error: 8.8049 - val_loss: 9.7582 - val_mean_absolute_error: 10.4053\n",
            "Epoch 51/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1263 - mean_absolute_error: 8.7631 - val_loss: 9.1423 - val_mean_absolute_error: 9.7729\n",
            "Epoch 52/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.1418 - mean_absolute_error: 8.7790 - val_loss: 10.8255 - val_mean_absolute_error: 11.4856\n",
            "Epoch 53/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.1752 - mean_absolute_error: 8.8134 - val_loss: 10.1130 - val_mean_absolute_error: 10.7658\n",
            "Epoch 54/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1223 - mean_absolute_error: 8.7590 - val_loss: 9.4052 - val_mean_absolute_error: 10.0526\n",
            "Epoch 55/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1533 - mean_absolute_error: 8.7913 - val_loss: 9.6530 - val_mean_absolute_error: 10.3010\n",
            "Epoch 56/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0794 - mean_absolute_error: 8.7161 - val_loss: 9.5265 - val_mean_absolute_error: 10.1300\n",
            "Epoch 57/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1242 - mean_absolute_error: 8.7609 - val_loss: 9.7974 - val_mean_absolute_error: 10.4392\n",
            "Epoch 58/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1812 - mean_absolute_error: 8.8194 - val_loss: 9.4640 - val_mean_absolute_error: 10.1036\n",
            "Epoch 59/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0512 - mean_absolute_error: 8.6875 - val_loss: 9.5995 - val_mean_absolute_error: 10.2355\n",
            "Epoch 60/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1319 - mean_absolute_error: 8.7696 - val_loss: 9.9462 - val_mean_absolute_error: 10.6039\n",
            "Epoch 61/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0980 - mean_absolute_error: 8.7359 - val_loss: 9.0871 - val_mean_absolute_error: 9.7406\n",
            "Epoch 62/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.1108 - mean_absolute_error: 8.7491 - val_loss: 9.0457 - val_mean_absolute_error: 9.7027\n",
            "Epoch 63/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.0377 - mean_absolute_error: 8.6738 - val_loss: 8.9032 - val_mean_absolute_error: 9.5560\n",
            "Epoch 64/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0188 - mean_absolute_error: 8.6552 - val_loss: 8.3527 - val_mean_absolute_error: 8.9937\n",
            "Epoch 65/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.0689 - mean_absolute_error: 8.7058 - val_loss: 8.3840 - val_mean_absolute_error: 9.0296\n",
            "Epoch 66/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 8.0752 - mean_absolute_error: 8.7120 - val_loss: 8.7008 - val_mean_absolute_error: 9.3467\n",
            "Epoch 67/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0190 - mean_absolute_error: 8.6546 - val_loss: 8.9772 - val_mean_absolute_error: 9.6331\n",
            "Epoch 68/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.0254 - mean_absolute_error: 8.6619 - val_loss: 9.2616 - val_mean_absolute_error: 9.9102\n",
            "Epoch 69/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.0394 - mean_absolute_error: 8.6755 - val_loss: 9.0796 - val_mean_absolute_error: 9.7069\n",
            "Epoch 70/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0290 - mean_absolute_error: 8.6645 - val_loss: 9.2535 - val_mean_absolute_error: 9.8974\n",
            "Epoch 71/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0511 - mean_absolute_error: 8.6881 - val_loss: 8.8604 - val_mean_absolute_error: 9.5068\n",
            "Epoch 72/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9930 - mean_absolute_error: 8.6294 - val_loss: 10.2382 - val_mean_absolute_error: 10.8910\n",
            "Epoch 73/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0473 - mean_absolute_error: 8.6838 - val_loss: 9.1412 - val_mean_absolute_error: 9.7942\n",
            "Epoch 74/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 8.0733 - mean_absolute_error: 8.7103 - val_loss: 8.8324 - val_mean_absolute_error: 9.4792\n",
            "Epoch 75/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9725 - mean_absolute_error: 8.6085 - val_loss: 8.5191 - val_mean_absolute_error: 9.1717\n",
            "Epoch 76/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9563 - mean_absolute_error: 8.5916 - val_loss: 8.4483 - val_mean_absolute_error: 9.0788\n",
            "Epoch 77/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9993 - mean_absolute_error: 8.6353 - val_loss: 8.5149 - val_mean_absolute_error: 9.1624\n",
            "Epoch 78/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9276 - mean_absolute_error: 8.5630 - val_loss: 9.0986 - val_mean_absolute_error: 9.7408\n",
            "Epoch 79/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9688 - mean_absolute_error: 8.6041 - val_loss: 8.7903 - val_mean_absolute_error: 9.4271\n",
            "Epoch 80/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9586 - mean_absolute_error: 8.5944 - val_loss: 9.0137 - val_mean_absolute_error: 9.6623\n",
            "Epoch 81/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9681 - mean_absolute_error: 8.6041 - val_loss: 8.6827 - val_mean_absolute_error: 9.3253\n",
            "Epoch 82/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9952 - mean_absolute_error: 8.6309 - val_loss: 9.2939 - val_mean_absolute_error: 9.9240\n",
            "Epoch 83/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9813 - mean_absolute_error: 8.6171 - val_loss: 8.9857 - val_mean_absolute_error: 9.6303\n",
            "Epoch 84/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 8.0168 - mean_absolute_error: 8.6524 - val_loss: 10.0250 - val_mean_absolute_error: 10.6847\n",
            "Epoch 85/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9258 - mean_absolute_error: 8.5608 - val_loss: 8.7511 - val_mean_absolute_error: 9.4026\n",
            "Epoch 86/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9271 - mean_absolute_error: 8.5620 - val_loss: 9.2549 - val_mean_absolute_error: 9.9135\n",
            "Epoch 87/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9388 - mean_absolute_error: 8.5742 - val_loss: 8.7778 - val_mean_absolute_error: 9.4173\n",
            "Epoch 88/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9429 - mean_absolute_error: 8.5775 - val_loss: 8.8785 - val_mean_absolute_error: 9.5271\n",
            "Epoch 89/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9158 - mean_absolute_error: 8.5500 - val_loss: 8.9213 - val_mean_absolute_error: 9.5736\n",
            "Epoch 90/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9442 - mean_absolute_error: 8.5799 - val_loss: 9.0247 - val_mean_absolute_error: 9.6695\n",
            "Epoch 91/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9178 - mean_absolute_error: 8.5526 - val_loss: 9.1217 - val_mean_absolute_error: 9.7598\n",
            "Epoch 92/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.8684 - mean_absolute_error: 8.5022 - val_loss: 8.7540 - val_mean_absolute_error: 9.3987\n",
            "Epoch 93/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9242 - mean_absolute_error: 8.5600 - val_loss: 8.6529 - val_mean_absolute_error: 9.2879\n",
            "Epoch 94/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.9235 - mean_absolute_error: 8.5585 - val_loss: 8.6328 - val_mean_absolute_error: 9.2796\n",
            "Epoch 95/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9618 - mean_absolute_error: 8.5975 - val_loss: 9.3767 - val_mean_absolute_error: 10.0277\n",
            "Epoch 96/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8839 - mean_absolute_error: 8.5189 - val_loss: 8.9908 - val_mean_absolute_error: 9.6385\n",
            "Epoch 97/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9286 - mean_absolute_error: 8.5632 - val_loss: 9.7363 - val_mean_absolute_error: 10.4006\n",
            "Epoch 98/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9118 - mean_absolute_error: 8.5468 - val_loss: 9.1417 - val_mean_absolute_error: 9.7991\n",
            "Epoch 99/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9175 - mean_absolute_error: 8.5513 - val_loss: 8.9576 - val_mean_absolute_error: 9.6051\n",
            "Epoch 100/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8478 - mean_absolute_error: 8.4818 - val_loss: 9.4394 - val_mean_absolute_error: 10.0847\n",
            "Epoch 101/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8527 - mean_absolute_error: 8.4865 - val_loss: 8.9053 - val_mean_absolute_error: 9.5628\n",
            "Epoch 102/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8588 - mean_absolute_error: 8.4929 - val_loss: 8.5246 - val_mean_absolute_error: 9.1676\n",
            "Epoch 103/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8825 - mean_absolute_error: 8.5176 - val_loss: 9.2005 - val_mean_absolute_error: 9.8592\n",
            "Epoch 104/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8494 - mean_absolute_error: 8.4843 - val_loss: 8.6697 - val_mean_absolute_error: 9.3124\n",
            "Epoch 105/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8617 - mean_absolute_error: 8.4963 - val_loss: 9.0334 - val_mean_absolute_error: 9.6873\n",
            "Epoch 106/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.9194 - mean_absolute_error: 8.5551 - val_loss: 9.4448 - val_mean_absolute_error: 10.0946\n",
            "Epoch 107/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8414 - mean_absolute_error: 8.4751 - val_loss: 8.6103 - val_mean_absolute_error: 9.2598\n",
            "Epoch 108/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8676 - mean_absolute_error: 8.5020 - val_loss: 8.4858 - val_mean_absolute_error: 9.1296\n",
            "Epoch 109/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8530 - mean_absolute_error: 8.4872 - val_loss: 9.1554 - val_mean_absolute_error: 9.8088\n",
            "Epoch 110/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8336 - mean_absolute_error: 8.4670 - val_loss: 8.7852 - val_mean_absolute_error: 9.4299\n",
            "Epoch 111/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8513 - mean_absolute_error: 8.4858 - val_loss: 10.3493 - val_mean_absolute_error: 11.0120\n",
            "Epoch 112/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8896 - mean_absolute_error: 8.5235 - val_loss: 8.6742 - val_mean_absolute_error: 9.3250\n",
            "Epoch 113/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8590 - mean_absolute_error: 8.4933 - val_loss: 8.3949 - val_mean_absolute_error: 9.0421\n",
            "Epoch 114/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8136 - mean_absolute_error: 8.4474 - val_loss: 9.0781 - val_mean_absolute_error: 9.7284\n",
            "Epoch 115/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8627 - mean_absolute_error: 8.4969 - val_loss: 8.8125 - val_mean_absolute_error: 9.4683\n",
            "Epoch 116/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8903 - mean_absolute_error: 8.5251 - val_loss: 8.4751 - val_mean_absolute_error: 9.1215\n",
            "Epoch 117/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8283 - mean_absolute_error: 8.4630 - val_loss: 8.9122 - val_mean_absolute_error: 9.5573\n",
            "Epoch 118/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8406 - mean_absolute_error: 8.4749 - val_loss: 8.6634 - val_mean_absolute_error: 9.3169\n",
            "Epoch 119/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8504 - mean_absolute_error: 8.4855 - val_loss: 9.3103 - val_mean_absolute_error: 9.9404\n",
            "Epoch 120/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8840 - mean_absolute_error: 8.5185 - val_loss: 9.2234 - val_mean_absolute_error: 9.8693\n",
            "Epoch 121/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8216 - mean_absolute_error: 8.4555 - val_loss: 8.4544 - val_mean_absolute_error: 9.0981\n",
            "Epoch 122/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8438 - mean_absolute_error: 8.4778 - val_loss: 10.7474 - val_mean_absolute_error: 11.4076\n",
            "Epoch 123/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8558 - mean_absolute_error: 8.4899 - val_loss: 9.9886 - val_mean_absolute_error: 10.6553\n",
            "Epoch 124/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8602 - mean_absolute_error: 8.4946 - val_loss: 8.6050 - val_mean_absolute_error: 9.2588\n",
            "Epoch 125/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8143 - mean_absolute_error: 8.4477 - val_loss: 9.1130 - val_mean_absolute_error: 9.7749\n",
            "Epoch 126/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8333 - mean_absolute_error: 8.4679 - val_loss: 8.9729 - val_mean_absolute_error: 9.6304\n",
            "Epoch 127/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 7.8156 - mean_absolute_error: 8.4488 - val_loss: 8.9713 - val_mean_absolute_error: 9.6242\n",
            "Epoch 128/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 7.8603 - mean_absolute_error: 8.4948 - val_loss: 8.7770 - val_mean_absolute_error: 9.4167\n",
            "Epoch 129/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8475 - mean_absolute_error: 8.4821 - val_loss: 9.0689 - val_mean_absolute_error: 9.7282\n",
            "Epoch 130/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7890 - mean_absolute_error: 8.4219 - val_loss: 8.9054 - val_mean_absolute_error: 9.5443\n",
            "Epoch 131/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7666 - mean_absolute_error: 8.3997 - val_loss: 9.0007 - val_mean_absolute_error: 9.6442\n",
            "Epoch 132/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7696 - mean_absolute_error: 8.4019 - val_loss: 8.9454 - val_mean_absolute_error: 9.5972\n",
            "Epoch 133/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8405 - mean_absolute_error: 8.4741 - val_loss: 9.0271 - val_mean_absolute_error: 9.6709\n",
            "Epoch 134/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7850 - mean_absolute_error: 8.4176 - val_loss: 8.8464 - val_mean_absolute_error: 9.4839\n",
            "Epoch 135/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7885 - mean_absolute_error: 8.4214 - val_loss: 9.1981 - val_mean_absolute_error: 9.8467\n",
            "Epoch 136/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8053 - mean_absolute_error: 8.4388 - val_loss: 9.1716 - val_mean_absolute_error: 9.8192\n",
            "Epoch 137/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7905 - mean_absolute_error: 8.4234 - val_loss: 9.1429 - val_mean_absolute_error: 9.7911\n",
            "Epoch 138/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7926 - mean_absolute_error: 8.4256 - val_loss: 9.1701 - val_mean_absolute_error: 9.8251\n",
            "Epoch 139/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7463 - mean_absolute_error: 8.3786 - val_loss: 8.8388 - val_mean_absolute_error: 9.4833\n",
            "Epoch 140/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7588 - mean_absolute_error: 8.3921 - val_loss: 8.8271 - val_mean_absolute_error: 9.4724\n",
            "Epoch 141/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7948 - mean_absolute_error: 8.4281 - val_loss: 8.7619 - val_mean_absolute_error: 9.4189\n",
            "Epoch 142/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8723 - mean_absolute_error: 8.5065 - val_loss: 8.6871 - val_mean_absolute_error: 9.3318\n",
            "Epoch 143/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7614 - mean_absolute_error: 8.3936 - val_loss: 8.9657 - val_mean_absolute_error: 9.6151\n",
            "Epoch 144/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7981 - mean_absolute_error: 8.4306 - val_loss: 10.1116 - val_mean_absolute_error: 10.7729\n",
            "Epoch 145/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7455 - mean_absolute_error: 8.3781 - val_loss: 8.9139 - val_mean_absolute_error: 9.5582\n",
            "Epoch 146/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8055 - mean_absolute_error: 8.4385 - val_loss: 8.7620 - val_mean_absolute_error: 9.4075\n",
            "Epoch 147/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7413 - mean_absolute_error: 8.3737 - val_loss: 8.9505 - val_mean_absolute_error: 9.5989\n",
            "Epoch 148/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8114 - mean_absolute_error: 8.4443 - val_loss: 8.6199 - val_mean_absolute_error: 9.2752\n",
            "Epoch 149/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7927 - mean_absolute_error: 8.4253 - val_loss: 8.5857 - val_mean_absolute_error: 9.2260\n",
            "Epoch 150/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7753 - mean_absolute_error: 8.4086 - val_loss: 9.1247 - val_mean_absolute_error: 9.7834\n",
            "Epoch 151/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7397 - mean_absolute_error: 8.3724 - val_loss: 8.5481 - val_mean_absolute_error: 9.1787\n",
            "Epoch 152/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.8003 - mean_absolute_error: 8.4326 - val_loss: 8.7524 - val_mean_absolute_error: 9.4112\n",
            "Epoch 153/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7553 - mean_absolute_error: 8.3877 - val_loss: 9.0310 - val_mean_absolute_error: 9.6716\n",
            "Epoch 154/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7700 - mean_absolute_error: 8.4029 - val_loss: 9.0762 - val_mean_absolute_error: 9.7326\n",
            "Epoch 155/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 7.7314 - mean_absolute_error: 8.3627 - val_loss: 9.0953 - val_mean_absolute_error: 9.7499\n",
            "Epoch 156/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7251 - mean_absolute_error: 8.3569 - val_loss: 9.2429 - val_mean_absolute_error: 9.8933\n",
            "Epoch 157/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7510 - mean_absolute_error: 8.3830 - val_loss: 8.6194 - val_mean_absolute_error: 9.2665\n",
            "Epoch 158/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7890 - mean_absolute_error: 8.4212 - val_loss: 8.9757 - val_mean_absolute_error: 9.6233\n",
            "Epoch 159/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7479 - mean_absolute_error: 8.3804 - val_loss: 9.1190 - val_mean_absolute_error: 9.7682\n",
            "Epoch 160/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 7.7848 - mean_absolute_error: 8.4177 - val_loss: 8.7399 - val_mean_absolute_error: 9.3926\n",
            "Epoch 161/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6942 - mean_absolute_error: 8.3260 - val_loss: 8.2108 - val_mean_absolute_error: 8.8654\n",
            "Epoch 162/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7429 - mean_absolute_error: 8.3744 - val_loss: 8.8994 - val_mean_absolute_error: 9.5577\n",
            "Epoch 163/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7490 - mean_absolute_error: 8.3804 - val_loss: 8.9616 - val_mean_absolute_error: 9.6051\n",
            "Epoch 164/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6699 - mean_absolute_error: 8.3020 - val_loss: 9.1955 - val_mean_absolute_error: 9.8438\n",
            "Epoch 165/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7676 - mean_absolute_error: 8.4000 - val_loss: 9.1541 - val_mean_absolute_error: 9.8077\n",
            "Epoch 166/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7015 - mean_absolute_error: 8.3331 - val_loss: 8.9916 - val_mean_absolute_error: 9.6362\n",
            "Epoch 167/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7386 - mean_absolute_error: 8.3708 - val_loss: 8.9995 - val_mean_absolute_error: 9.6518\n",
            "Epoch 168/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7230 - mean_absolute_error: 8.3547 - val_loss: 9.3602 - val_mean_absolute_error: 9.9978\n",
            "Epoch 169/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6804 - mean_absolute_error: 8.3121 - val_loss: 8.7299 - val_mean_absolute_error: 9.3619\n",
            "Epoch 170/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7041 - mean_absolute_error: 8.3360 - val_loss: 8.8375 - val_mean_absolute_error: 9.4818\n",
            "Epoch 171/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7377 - mean_absolute_error: 8.3693 - val_loss: 9.0028 - val_mean_absolute_error: 9.6575\n",
            "Epoch 172/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7099 - mean_absolute_error: 8.3418 - val_loss: 8.5762 - val_mean_absolute_error: 9.2228\n",
            "Epoch 173/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6743 - mean_absolute_error: 8.3057 - val_loss: 8.7798 - val_mean_absolute_error: 9.4348\n",
            "Epoch 174/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6585 - mean_absolute_error: 8.2899 - val_loss: 8.9990 - val_mean_absolute_error: 9.6574\n",
            "Epoch 175/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7163 - mean_absolute_error: 8.3485 - val_loss: 8.7565 - val_mean_absolute_error: 9.4016\n",
            "Epoch 176/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6962 - mean_absolute_error: 8.3272 - val_loss: 9.4362 - val_mean_absolute_error: 10.0955\n",
            "Epoch 177/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6857 - mean_absolute_error: 8.3169 - val_loss: 9.4209 - val_mean_absolute_error: 10.0786\n",
            "Epoch 178/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7072 - mean_absolute_error: 8.3387 - val_loss: 10.5152 - val_mean_absolute_error: 11.1748\n",
            "Epoch 179/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7276 - mean_absolute_error: 8.3600 - val_loss: 9.7197 - val_mean_absolute_error: 10.3703\n",
            "Epoch 180/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7021 - mean_absolute_error: 8.3343 - val_loss: 9.0304 - val_mean_absolute_error: 9.6746\n",
            "Epoch 181/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6679 - mean_absolute_error: 8.2993 - val_loss: 8.9097 - val_mean_absolute_error: 9.5587\n",
            "Epoch 182/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7116 - mean_absolute_error: 8.3435 - val_loss: 9.4485 - val_mean_absolute_error: 10.1068\n",
            "Epoch 183/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7216 - mean_absolute_error: 8.3531 - val_loss: 9.2486 - val_mean_absolute_error: 9.8987\n",
            "Epoch 184/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6873 - mean_absolute_error: 8.3190 - val_loss: 8.9159 - val_mean_absolute_error: 9.5528\n",
            "Epoch 185/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7152 - mean_absolute_error: 8.3463 - val_loss: 9.1522 - val_mean_absolute_error: 9.8058\n",
            "Epoch 186/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6775 - mean_absolute_error: 8.3086 - val_loss: 9.6224 - val_mean_absolute_error: 10.2784\n",
            "Epoch 187/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6516 - mean_absolute_error: 8.2828 - val_loss: 10.0727 - val_mean_absolute_error: 10.7300\n",
            "Epoch 188/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6867 - mean_absolute_error: 8.3176 - val_loss: 9.4606 - val_mean_absolute_error: 10.1051\n",
            "Epoch 189/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6678 - mean_absolute_error: 8.2982 - val_loss: 10.0993 - val_mean_absolute_error: 10.7551\n",
            "Epoch 190/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6895 - mean_absolute_error: 8.3208 - val_loss: 10.7037 - val_mean_absolute_error: 11.3657\n",
            "Epoch 191/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6959 - mean_absolute_error: 8.3271 - val_loss: 10.2378 - val_mean_absolute_error: 10.8767\n",
            "Epoch 192/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7194 - mean_absolute_error: 8.3505 - val_loss: 9.5150 - val_mean_absolute_error: 10.1552\n",
            "Epoch 193/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6448 - mean_absolute_error: 8.2748 - val_loss: 9.3039 - val_mean_absolute_error: 9.9590\n",
            "Epoch 194/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6417 - mean_absolute_error: 8.2722 - val_loss: 8.7631 - val_mean_absolute_error: 9.4159\n",
            "Epoch 195/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7082 - mean_absolute_error: 8.3385 - val_loss: 9.0579 - val_mean_absolute_error: 9.7140\n",
            "Epoch 196/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7017 - mean_absolute_error: 8.3326 - val_loss: 9.1021 - val_mean_absolute_error: 9.7622\n",
            "Epoch 197/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6958 - mean_absolute_error: 8.3269 - val_loss: 9.6427 - val_mean_absolute_error: 10.3046\n",
            "Epoch 198/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6267 - mean_absolute_error: 8.2573 - val_loss: 8.5982 - val_mean_absolute_error: 9.2505\n",
            "Epoch 199/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6592 - mean_absolute_error: 8.2905 - val_loss: 9.0625 - val_mean_absolute_error: 9.7163\n",
            "Epoch 200/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.7332 - mean_absolute_error: 8.3649 - val_loss: 9.1827 - val_mean_absolute_error: 9.8254\n",
            "Epoch 201/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6599 - mean_absolute_error: 8.2915 - val_loss: 9.4912 - val_mean_absolute_error: 10.1451\n",
            "Epoch 202/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6800 - mean_absolute_error: 8.3112 - val_loss: 8.5972 - val_mean_absolute_error: 9.2398\n",
            "Epoch 203/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6600 - mean_absolute_error: 8.2911 - val_loss: 9.0613 - val_mean_absolute_error: 9.7070\n",
            "Epoch 204/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6924 - mean_absolute_error: 8.3234 - val_loss: 9.2881 - val_mean_absolute_error: 9.9339\n",
            "Epoch 205/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6697 - mean_absolute_error: 8.2998 - val_loss: 7.9388 - val_mean_absolute_error: 8.5675\n",
            "Epoch 206/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6593 - mean_absolute_error: 8.2898 - val_loss: 9.1294 - val_mean_absolute_error: 9.7814\n",
            "Epoch 207/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6154 - mean_absolute_error: 8.2456 - val_loss: 9.3659 - val_mean_absolute_error: 10.0201\n",
            "Epoch 208/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6687 - mean_absolute_error: 8.2992 - val_loss: 8.5367 - val_mean_absolute_error: 9.1926\n",
            "Epoch 209/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6448 - mean_absolute_error: 8.2755 - val_loss: 8.8285 - val_mean_absolute_error: 9.4772\n",
            "Epoch 210/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6784 - mean_absolute_error: 8.3091 - val_loss: 8.7402 - val_mean_absolute_error: 9.3796\n",
            "Epoch 211/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5944 - mean_absolute_error: 8.2249 - val_loss: 9.4660 - val_mean_absolute_error: 10.1197\n",
            "Epoch 212/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6310 - mean_absolute_error: 8.2614 - val_loss: 9.2806 - val_mean_absolute_error: 9.9289\n",
            "Epoch 213/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6868 - mean_absolute_error: 8.3179 - val_loss: 9.5904 - val_mean_absolute_error: 10.2268\n",
            "Epoch 214/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6674 - mean_absolute_error: 8.2980 - val_loss: 8.6252 - val_mean_absolute_error: 9.2713\n",
            "Epoch 215/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6522 - mean_absolute_error: 8.2826 - val_loss: 8.7785 - val_mean_absolute_error: 9.4247\n",
            "Epoch 216/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6105 - mean_absolute_error: 8.2400 - val_loss: 8.8529 - val_mean_absolute_error: 9.5112\n",
            "Epoch 217/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6652 - mean_absolute_error: 8.2958 - val_loss: 9.5149 - val_mean_absolute_error: 10.1712\n",
            "Epoch 218/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6035 - mean_absolute_error: 8.2335 - val_loss: 8.7448 - val_mean_absolute_error: 9.3767\n",
            "Epoch 219/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6361 - mean_absolute_error: 8.2663 - val_loss: 9.8706 - val_mean_absolute_error: 10.5263\n",
            "Epoch 220/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6212 - mean_absolute_error: 8.2513 - val_loss: 10.0670 - val_mean_absolute_error: 10.7242\n",
            "Epoch 221/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5991 - mean_absolute_error: 8.2292 - val_loss: 9.2036 - val_mean_absolute_error: 9.8574\n",
            "Epoch 222/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5903 - mean_absolute_error: 8.2196 - val_loss: 9.1593 - val_mean_absolute_error: 9.7973\n",
            "Epoch 223/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6250 - mean_absolute_error: 8.2551 - val_loss: 8.5235 - val_mean_absolute_error: 9.1698\n",
            "Epoch 224/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6412 - mean_absolute_error: 8.2720 - val_loss: 10.0536 - val_mean_absolute_error: 10.7150\n",
            "Epoch 225/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6042 - mean_absolute_error: 8.2336 - val_loss: 10.2147 - val_mean_absolute_error: 10.8750\n",
            "Epoch 226/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6697 - mean_absolute_error: 8.3003 - val_loss: 9.5815 - val_mean_absolute_error: 10.2306\n",
            "Epoch 227/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6187 - mean_absolute_error: 8.2492 - val_loss: 9.2526 - val_mean_absolute_error: 9.9024\n",
            "Epoch 228/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6915 - mean_absolute_error: 8.3221 - val_loss: 10.6662 - val_mean_absolute_error: 11.3158\n",
            "Epoch 229/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6334 - mean_absolute_error: 8.2638 - val_loss: 9.3098 - val_mean_absolute_error: 9.9604\n",
            "Epoch 230/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5940 - mean_absolute_error: 8.2235 - val_loss: 9.5554 - val_mean_absolute_error: 10.1802\n",
            "Epoch 231/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6294 - mean_absolute_error: 8.2593 - val_loss: 9.9090 - val_mean_absolute_error: 10.5576\n",
            "Epoch 232/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5972 - mean_absolute_error: 8.2272 - val_loss: 9.9964 - val_mean_absolute_error: 10.6453\n",
            "Epoch 233/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5865 - mean_absolute_error: 8.2163 - val_loss: 10.0554 - val_mean_absolute_error: 10.7142\n",
            "Epoch 234/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6079 - mean_absolute_error: 8.2377 - val_loss: 9.6463 - val_mean_absolute_error: 10.2856\n",
            "Epoch 235/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5965 - mean_absolute_error: 8.2274 - val_loss: 9.8338 - val_mean_absolute_error: 10.4790\n",
            "Epoch 236/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6061 - mean_absolute_error: 8.2363 - val_loss: 10.1100 - val_mean_absolute_error: 10.7630\n",
            "Epoch 237/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5630 - mean_absolute_error: 8.1925 - val_loss: 9.2814 - val_mean_absolute_error: 9.9112\n",
            "Epoch 238/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6099 - mean_absolute_error: 8.2406 - val_loss: 9.5710 - val_mean_absolute_error: 10.2210\n",
            "Epoch 239/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5873 - mean_absolute_error: 8.2168 - val_loss: 9.4248 - val_mean_absolute_error: 10.0449\n",
            "Epoch 240/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5994 - mean_absolute_error: 8.2295 - val_loss: 9.3456 - val_mean_absolute_error: 10.0011\n",
            "Epoch 241/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5581 - mean_absolute_error: 8.1873 - val_loss: 8.6375 - val_mean_absolute_error: 9.2963\n",
            "Epoch 242/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5946 - mean_absolute_error: 8.2242 - val_loss: 9.9305 - val_mean_absolute_error: 10.5859\n",
            "Epoch 243/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6631 - mean_absolute_error: 8.2934 - val_loss: 10.1996 - val_mean_absolute_error: 10.8594\n",
            "Epoch 244/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6601 - mean_absolute_error: 8.2902 - val_loss: 9.0668 - val_mean_absolute_error: 9.7193\n",
            "Epoch 245/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5790 - mean_absolute_error: 8.2093 - val_loss: 9.3149 - val_mean_absolute_error: 9.9533\n",
            "Epoch 246/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5784 - mean_absolute_error: 8.2074 - val_loss: 9.6000 - val_mean_absolute_error: 10.2381\n",
            "Epoch 247/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5751 - mean_absolute_error: 8.2044 - val_loss: 9.6208 - val_mean_absolute_error: 10.2663\n",
            "Epoch 248/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5723 - mean_absolute_error: 8.2013 - val_loss: 9.2042 - val_mean_absolute_error: 9.8543\n",
            "Epoch 249/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5830 - mean_absolute_error: 8.2125 - val_loss: 9.5377 - val_mean_absolute_error: 10.1698\n",
            "Epoch 250/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5831 - mean_absolute_error: 8.2130 - val_loss: 9.1757 - val_mean_absolute_error: 9.8204\n",
            "Epoch 251/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6171 - mean_absolute_error: 8.2480 - val_loss: 10.3099 - val_mean_absolute_error: 10.9698\n",
            "Epoch 252/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5833 - mean_absolute_error: 8.2135 - val_loss: 9.9809 - val_mean_absolute_error: 10.6456\n",
            "Epoch 253/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6169 - mean_absolute_error: 8.2477 - val_loss: 9.7381 - val_mean_absolute_error: 10.3789\n",
            "Epoch 254/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6403 - mean_absolute_error: 8.2703 - val_loss: 8.8331 - val_mean_absolute_error: 9.4979\n",
            "Epoch 255/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6503 - mean_absolute_error: 8.2810 - val_loss: 9.4939 - val_mean_absolute_error: 10.1340\n",
            "Epoch 256/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5718 - mean_absolute_error: 8.2013 - val_loss: 9.8259 - val_mean_absolute_error: 10.4821\n",
            "Epoch 257/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5602 - mean_absolute_error: 8.1893 - val_loss: 9.3748 - val_mean_absolute_error: 10.0287\n",
            "Epoch 258/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5968 - mean_absolute_error: 8.2266 - val_loss: 8.5811 - val_mean_absolute_error: 9.2286\n",
            "Epoch 259/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5893 - mean_absolute_error: 8.2187 - val_loss: 10.4395 - val_mean_absolute_error: 11.0856\n",
            "Epoch 260/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6186 - mean_absolute_error: 8.2480 - val_loss: 9.9202 - val_mean_absolute_error: 10.5717\n",
            "Epoch 261/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5900 - mean_absolute_error: 8.2197 - val_loss: 9.9433 - val_mean_absolute_error: 10.5948\n",
            "Epoch 262/500\n",
            "178160/178160 [==============================] - 12s 66us/step - loss: 7.5899 - mean_absolute_error: 8.2193 - val_loss: 9.1666 - val_mean_absolute_error: 9.8105\n",
            "Epoch 263/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5622 - mean_absolute_error: 8.1911 - val_loss: 9.5239 - val_mean_absolute_error: 10.1677\n",
            "Epoch 264/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.6326 - mean_absolute_error: 8.2627 - val_loss: 9.8665 - val_mean_absolute_error: 10.5107\n",
            "Epoch 265/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5853 - mean_absolute_error: 8.2149 - val_loss: 9.8519 - val_mean_absolute_error: 10.5040\n",
            "Epoch 266/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5804 - mean_absolute_error: 8.2097 - val_loss: 9.7098 - val_mean_absolute_error: 10.3361\n",
            "Epoch 267/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5810 - mean_absolute_error: 8.2108 - val_loss: 10.3097 - val_mean_absolute_error: 10.9582\n",
            "Epoch 268/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5567 - mean_absolute_error: 8.1871 - val_loss: 9.8453 - val_mean_absolute_error: 10.4971\n",
            "Epoch 269/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5833 - mean_absolute_error: 8.2124 - val_loss: 9.9530 - val_mean_absolute_error: 10.5861\n",
            "Epoch 270/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5897 - mean_absolute_error: 8.2185 - val_loss: 9.5890 - val_mean_absolute_error: 10.2341\n",
            "Epoch 271/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6020 - mean_absolute_error: 8.2319 - val_loss: 9.3240 - val_mean_absolute_error: 9.9576\n",
            "Epoch 272/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5954 - mean_absolute_error: 8.2244 - val_loss: 9.8207 - val_mean_absolute_error: 10.4582\n",
            "Epoch 273/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5471 - mean_absolute_error: 8.1762 - val_loss: 10.0553 - val_mean_absolute_error: 10.7013\n",
            "Epoch 274/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5685 - mean_absolute_error: 8.1978 - val_loss: 10.0552 - val_mean_absolute_error: 10.7134\n",
            "Epoch 275/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6100 - mean_absolute_error: 8.2393 - val_loss: 10.6632 - val_mean_absolute_error: 11.3160\n",
            "Epoch 276/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6229 - mean_absolute_error: 8.2527 - val_loss: 10.6253 - val_mean_absolute_error: 11.2785\n",
            "Epoch 277/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5504 - mean_absolute_error: 8.1784 - val_loss: 9.9176 - val_mean_absolute_error: 10.5719\n",
            "Epoch 278/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5703 - mean_absolute_error: 8.1991 - val_loss: 9.8444 - val_mean_absolute_error: 10.4831\n",
            "Epoch 279/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.6300 - mean_absolute_error: 8.2593 - val_loss: 10.2155 - val_mean_absolute_error: 10.8539\n",
            "Epoch 280/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5483 - mean_absolute_error: 8.1774 - val_loss: 8.5843 - val_mean_absolute_error: 9.2251\n",
            "Epoch 281/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5947 - mean_absolute_error: 8.2246 - val_loss: 9.2469 - val_mean_absolute_error: 9.8790\n",
            "Epoch 282/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5931 - mean_absolute_error: 8.2223 - val_loss: 10.1968 - val_mean_absolute_error: 10.8332\n",
            "Epoch 283/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5447 - mean_absolute_error: 8.1741 - val_loss: 10.1646 - val_mean_absolute_error: 10.8159\n",
            "Epoch 284/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5388 - mean_absolute_error: 8.1680 - val_loss: 8.6416 - val_mean_absolute_error: 9.2827\n",
            "Epoch 285/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5642 - mean_absolute_error: 8.1938 - val_loss: 9.9376 - val_mean_absolute_error: 10.5783\n",
            "Epoch 286/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5526 - mean_absolute_error: 8.1813 - val_loss: 9.6295 - val_mean_absolute_error: 10.2596\n",
            "Epoch 287/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5800 - mean_absolute_error: 8.2089 - val_loss: 8.5976 - val_mean_absolute_error: 9.2492\n",
            "Epoch 288/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5496 - mean_absolute_error: 8.1781 - val_loss: 9.1604 - val_mean_absolute_error: 9.8028\n",
            "Epoch 289/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5108 - mean_absolute_error: 8.1389 - val_loss: 10.5671 - val_mean_absolute_error: 11.2256\n",
            "Epoch 290/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5459 - mean_absolute_error: 8.1743 - val_loss: 9.3206 - val_mean_absolute_error: 9.9572\n",
            "Epoch 291/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5475 - mean_absolute_error: 8.1762 - val_loss: 10.8278 - val_mean_absolute_error: 11.4610\n",
            "Epoch 292/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5713 - mean_absolute_error: 8.2003 - val_loss: 9.9405 - val_mean_absolute_error: 10.5878\n",
            "Epoch 293/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5481 - mean_absolute_error: 8.1774 - val_loss: 9.1977 - val_mean_absolute_error: 9.8280\n",
            "Epoch 294/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5698 - mean_absolute_error: 8.1993 - val_loss: 9.9475 - val_mean_absolute_error: 10.5981\n",
            "Epoch 295/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5363 - mean_absolute_error: 8.1648 - val_loss: 8.9613 - val_mean_absolute_error: 9.6052\n",
            "Epoch 296/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5478 - mean_absolute_error: 8.1763 - val_loss: 8.8762 - val_mean_absolute_error: 9.5160\n",
            "Epoch 297/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5077 - mean_absolute_error: 8.1356 - val_loss: 9.4274 - val_mean_absolute_error: 10.0801\n",
            "Epoch 298/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5519 - mean_absolute_error: 8.1807 - val_loss: 9.5793 - val_mean_absolute_error: 10.2166\n",
            "Epoch 299/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5668 - mean_absolute_error: 8.1960 - val_loss: 9.9739 - val_mean_absolute_error: 10.6245\n",
            "Epoch 300/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5283 - mean_absolute_error: 8.1563 - val_loss: 10.1984 - val_mean_absolute_error: 10.8522\n",
            "Epoch 301/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5269 - mean_absolute_error: 8.1558 - val_loss: 9.6548 - val_mean_absolute_error: 10.2897\n",
            "Epoch 302/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5481 - mean_absolute_error: 8.1762 - val_loss: 10.1127 - val_mean_absolute_error: 10.7543\n",
            "Epoch 303/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5360 - mean_absolute_error: 8.1636 - val_loss: 9.7348 - val_mean_absolute_error: 10.3717\n",
            "Epoch 304/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5774 - mean_absolute_error: 8.2053 - val_loss: 10.1698 - val_mean_absolute_error: 10.7893\n",
            "Epoch 305/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5314 - mean_absolute_error: 8.1596 - val_loss: 9.8979 - val_mean_absolute_error: 10.5327\n",
            "Epoch 306/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5470 - mean_absolute_error: 8.1750 - val_loss: 10.0850 - val_mean_absolute_error: 10.7417\n",
            "Epoch 307/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5418 - mean_absolute_error: 8.1707 - val_loss: 9.7818 - val_mean_absolute_error: 10.4332\n",
            "Epoch 308/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5635 - mean_absolute_error: 8.1924 - val_loss: 10.3153 - val_mean_absolute_error: 10.9690\n",
            "Epoch 309/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4873 - mean_absolute_error: 8.1155 - val_loss: 10.2355 - val_mean_absolute_error: 10.8751\n",
            "Epoch 310/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5385 - mean_absolute_error: 8.1664 - val_loss: 10.1306 - val_mean_absolute_error: 10.7822\n",
            "Epoch 311/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5215 - mean_absolute_error: 8.1500 - val_loss: 10.4871 - val_mean_absolute_error: 11.1397\n",
            "Epoch 312/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5450 - mean_absolute_error: 8.1735 - val_loss: 10.0176 - val_mean_absolute_error: 10.6551\n",
            "Epoch 313/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5253 - mean_absolute_error: 8.1530 - val_loss: 10.0476 - val_mean_absolute_error: 10.6818\n",
            "Epoch 314/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4781 - mean_absolute_error: 8.1056 - val_loss: 9.7761 - val_mean_absolute_error: 10.4085\n",
            "Epoch 315/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5811 - mean_absolute_error: 8.2096 - val_loss: 9.7934 - val_mean_absolute_error: 10.4355\n",
            "Epoch 316/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5490 - mean_absolute_error: 8.1768 - val_loss: 10.0322 - val_mean_absolute_error: 10.6781\n",
            "Epoch 317/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5577 - mean_absolute_error: 8.1864 - val_loss: 10.0568 - val_mean_absolute_error: 10.6881\n",
            "Epoch 318/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5168 - mean_absolute_error: 8.1447 - val_loss: 9.3986 - val_mean_absolute_error: 10.0354\n",
            "Epoch 319/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5183 - mean_absolute_error: 8.1469 - val_loss: 8.1314 - val_mean_absolute_error: 8.7697\n",
            "Epoch 320/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5686 - mean_absolute_error: 8.1968 - val_loss: 8.6040 - val_mean_absolute_error: 9.2412\n",
            "Epoch 321/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5433 - mean_absolute_error: 8.1710 - val_loss: 8.5690 - val_mean_absolute_error: 9.2076\n",
            "Epoch 322/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.5511 - mean_absolute_error: 8.1801 - val_loss: 9.3836 - val_mean_absolute_error: 10.0330\n",
            "Epoch 323/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5126 - mean_absolute_error: 8.1405 - val_loss: 9.9300 - val_mean_absolute_error: 10.5862\n",
            "Epoch 324/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5433 - mean_absolute_error: 8.1714 - val_loss: 9.8961 - val_mean_absolute_error: 10.5418\n",
            "Epoch 325/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5040 - mean_absolute_error: 8.1315 - val_loss: 9.6316 - val_mean_absolute_error: 10.2889\n",
            "Epoch 326/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5162 - mean_absolute_error: 8.1440 - val_loss: 9.1145 - val_mean_absolute_error: 9.7580\n",
            "Epoch 327/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5059 - mean_absolute_error: 8.1340 - val_loss: 7.8670 - val_mean_absolute_error: 8.5007\n",
            "Epoch 328/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5228 - mean_absolute_error: 8.1500 - val_loss: 8.4293 - val_mean_absolute_error: 9.0794\n",
            "Epoch 329/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5384 - mean_absolute_error: 8.1656 - val_loss: 8.2676 - val_mean_absolute_error: 8.9235\n",
            "Epoch 330/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5148 - mean_absolute_error: 8.1435 - val_loss: 9.7178 - val_mean_absolute_error: 10.3607\n",
            "Epoch 331/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5231 - mean_absolute_error: 8.1515 - val_loss: 11.0055 - val_mean_absolute_error: 11.6619\n",
            "Epoch 332/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5078 - mean_absolute_error: 8.1356 - val_loss: 9.9760 - val_mean_absolute_error: 10.6121\n",
            "Epoch 333/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5378 - mean_absolute_error: 8.1665 - val_loss: 10.1204 - val_mean_absolute_error: 10.7513\n",
            "Epoch 334/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5077 - mean_absolute_error: 8.1355 - val_loss: 8.2591 - val_mean_absolute_error: 8.8893\n",
            "Epoch 335/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5290 - mean_absolute_error: 8.1571 - val_loss: 8.5136 - val_mean_absolute_error: 9.1514\n",
            "Epoch 336/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5227 - mean_absolute_error: 8.1506 - val_loss: 8.8749 - val_mean_absolute_error: 9.5283\n",
            "Epoch 337/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5073 - mean_absolute_error: 8.1348 - val_loss: 9.0988 - val_mean_absolute_error: 9.7582\n",
            "Epoch 338/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5136 - mean_absolute_error: 8.1412 - val_loss: 7.9126 - val_mean_absolute_error: 8.5668\n",
            "Epoch 339/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5246 - mean_absolute_error: 8.1532 - val_loss: 8.2989 - val_mean_absolute_error: 8.9487\n",
            "Epoch 340/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4948 - mean_absolute_error: 8.1232 - val_loss: 8.1924 - val_mean_absolute_error: 8.8443\n",
            "Epoch 341/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5201 - mean_absolute_error: 8.1478 - val_loss: 8.0029 - val_mean_absolute_error: 8.6363\n",
            "Epoch 342/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5172 - mean_absolute_error: 8.1456 - val_loss: 8.1393 - val_mean_absolute_error: 8.7765\n",
            "Epoch 343/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4936 - mean_absolute_error: 8.1209 - val_loss: 7.7615 - val_mean_absolute_error: 8.3902\n",
            "Epoch 344/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5075 - mean_absolute_error: 8.1355 - val_loss: 7.8634 - val_mean_absolute_error: 8.4942\n",
            "Epoch 345/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4813 - mean_absolute_error: 8.1088 - val_loss: 8.3338 - val_mean_absolute_error: 8.9780\n",
            "Epoch 346/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5104 - mean_absolute_error: 8.1380 - val_loss: 8.0146 - val_mean_absolute_error: 8.6545\n",
            "Epoch 347/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4798 - mean_absolute_error: 8.1065 - val_loss: 8.0446 - val_mean_absolute_error: 8.6818\n",
            "Epoch 348/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4697 - mean_absolute_error: 8.0967 - val_loss: 8.2327 - val_mean_absolute_error: 8.8794\n",
            "Epoch 349/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5000 - mean_absolute_error: 8.1275 - val_loss: 7.6917 - val_mean_absolute_error: 8.3312\n",
            "Epoch 350/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4589 - mean_absolute_error: 8.0861 - val_loss: 8.3774 - val_mean_absolute_error: 9.0316\n",
            "Epoch 351/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4679 - mean_absolute_error: 8.0954 - val_loss: 8.1007 - val_mean_absolute_error: 8.7478\n",
            "Epoch 352/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5160 - mean_absolute_error: 8.1438 - val_loss: 8.1319 - val_mean_absolute_error: 8.7744\n",
            "Epoch 353/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5095 - mean_absolute_error: 8.1374 - val_loss: 8.3395 - val_mean_absolute_error: 8.9926\n",
            "Epoch 354/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5034 - mean_absolute_error: 8.1307 - val_loss: 8.5964 - val_mean_absolute_error: 9.2560\n",
            "Epoch 355/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5043 - mean_absolute_error: 8.1325 - val_loss: 8.2751 - val_mean_absolute_error: 8.9295\n",
            "Epoch 356/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4938 - mean_absolute_error: 8.1205 - val_loss: 8.2299 - val_mean_absolute_error: 8.8711\n",
            "Epoch 357/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4923 - mean_absolute_error: 8.1190 - val_loss: 8.1442 - val_mean_absolute_error: 8.7986\n",
            "Epoch 358/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5044 - mean_absolute_error: 8.1323 - val_loss: 8.3879 - val_mean_absolute_error: 9.0424\n",
            "Epoch 359/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5003 - mean_absolute_error: 8.1282 - val_loss: 8.4415 - val_mean_absolute_error: 9.0635\n",
            "Epoch 360/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5068 - mean_absolute_error: 8.1342 - val_loss: 8.2394 - val_mean_absolute_error: 8.8910\n",
            "Epoch 361/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4979 - mean_absolute_error: 8.1259 - val_loss: 7.8628 - val_mean_absolute_error: 8.5116\n",
            "Epoch 362/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5017 - mean_absolute_error: 8.1300 - val_loss: 7.9465 - val_mean_absolute_error: 8.5814\n",
            "Epoch 363/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4705 - mean_absolute_error: 8.0986 - val_loss: 8.4174 - val_mean_absolute_error: 9.0691\n",
            "Epoch 364/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4646 - mean_absolute_error: 8.0920 - val_loss: 8.0166 - val_mean_absolute_error: 8.6656\n",
            "Epoch 365/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4669 - mean_absolute_error: 8.0944 - val_loss: 7.6699 - val_mean_absolute_error: 8.2901\n",
            "Epoch 366/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4997 - mean_absolute_error: 8.1269 - val_loss: 8.1733 - val_mean_absolute_error: 8.8213\n",
            "Epoch 367/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4765 - mean_absolute_error: 8.1030 - val_loss: 8.0948 - val_mean_absolute_error: 8.7491\n",
            "Epoch 368/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4838 - mean_absolute_error: 8.1116 - val_loss: 8.2733 - val_mean_absolute_error: 8.9256\n",
            "Epoch 369/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5156 - mean_absolute_error: 8.1440 - val_loss: 7.9524 - val_mean_absolute_error: 8.5962\n",
            "Epoch 370/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4621 - mean_absolute_error: 8.0893 - val_loss: 7.7744 - val_mean_absolute_error: 8.4096\n",
            "Epoch 371/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.4992 - mean_absolute_error: 8.1263 - val_loss: 7.8074 - val_mean_absolute_error: 8.4335\n",
            "Epoch 372/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4730 - mean_absolute_error: 8.1006 - val_loss: 8.0135 - val_mean_absolute_error: 8.6576\n",
            "Epoch 373/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5233 - mean_absolute_error: 8.1517 - val_loss: 7.7537 - val_mean_absolute_error: 8.3970\n",
            "Epoch 374/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5594 - mean_absolute_error: 8.1880 - val_loss: 8.2281 - val_mean_absolute_error: 8.8814\n",
            "Epoch 375/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4686 - mean_absolute_error: 8.0964 - val_loss: 8.2775 - val_mean_absolute_error: 8.9280\n",
            "Epoch 376/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5025 - mean_absolute_error: 8.1295 - val_loss: 7.9504 - val_mean_absolute_error: 8.5980\n",
            "Epoch 377/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4615 - mean_absolute_error: 8.0894 - val_loss: 8.0684 - val_mean_absolute_error: 8.7104\n",
            "Epoch 378/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4776 - mean_absolute_error: 8.1059 - val_loss: 8.1266 - val_mean_absolute_error: 8.7713\n",
            "Epoch 379/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.5306 - mean_absolute_error: 8.1579 - val_loss: 8.2034 - val_mean_absolute_error: 8.8121\n",
            "Epoch 380/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4939 - mean_absolute_error: 8.1207 - val_loss: 8.6781 - val_mean_absolute_error: 9.3388\n",
            "Epoch 381/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5565 - mean_absolute_error: 8.1847 - val_loss: 7.9084 - val_mean_absolute_error: 8.5517\n",
            "Epoch 382/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5171 - mean_absolute_error: 8.1441 - val_loss: 7.6636 - val_mean_absolute_error: 8.3049\n",
            "Epoch 383/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4604 - mean_absolute_error: 8.0872 - val_loss: 8.4318 - val_mean_absolute_error: 9.0845\n",
            "Epoch 384/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4445 - mean_absolute_error: 8.0714 - val_loss: 8.0101 - val_mean_absolute_error: 8.6585\n",
            "Epoch 385/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4831 - mean_absolute_error: 8.1099 - val_loss: 7.9909 - val_mean_absolute_error: 8.6444\n",
            "Epoch 386/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4698 - mean_absolute_error: 8.0967 - val_loss: 8.0342 - val_mean_absolute_error: 8.6808\n",
            "Epoch 387/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4626 - mean_absolute_error: 8.0900 - val_loss: 8.2846 - val_mean_absolute_error: 8.9364\n",
            "Epoch 388/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5475 - mean_absolute_error: 8.1755 - val_loss: 7.9191 - val_mean_absolute_error: 8.5631\n",
            "Epoch 389/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4814 - mean_absolute_error: 8.1088 - val_loss: 7.9934 - val_mean_absolute_error: 8.6372\n",
            "Epoch 390/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5175 - mean_absolute_error: 8.1459 - val_loss: 7.9679 - val_mean_absolute_error: 8.6069\n",
            "Epoch 391/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4831 - mean_absolute_error: 8.1098 - val_loss: 8.8252 - val_mean_absolute_error: 9.4855\n",
            "Epoch 392/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4272 - mean_absolute_error: 8.0536 - val_loss: 8.1190 - val_mean_absolute_error: 8.7679\n",
            "Epoch 393/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4819 - mean_absolute_error: 8.1096 - val_loss: 8.5335 - val_mean_absolute_error: 9.1835\n",
            "Epoch 394/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4830 - mean_absolute_error: 8.1099 - val_loss: 8.2087 - val_mean_absolute_error: 8.8572\n",
            "Epoch 395/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4362 - mean_absolute_error: 8.0629 - val_loss: 8.3903 - val_mean_absolute_error: 9.0461\n",
            "Epoch 396/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4280 - mean_absolute_error: 8.0541 - val_loss: 8.2504 - val_mean_absolute_error: 8.9049\n",
            "Epoch 397/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4355 - mean_absolute_error: 8.0622 - val_loss: 8.0673 - val_mean_absolute_error: 8.7180\n",
            "Epoch 398/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.4787 - mean_absolute_error: 8.1061 - val_loss: 7.9134 - val_mean_absolute_error: 8.5649\n",
            "Epoch 399/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4396 - mean_absolute_error: 8.0659 - val_loss: 8.9156 - val_mean_absolute_error: 9.5706\n",
            "Epoch 400/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4921 - mean_absolute_error: 8.1192 - val_loss: 8.8949 - val_mean_absolute_error: 9.5581\n",
            "Epoch 401/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4586 - mean_absolute_error: 8.0857 - val_loss: 8.4589 - val_mean_absolute_error: 9.1183\n",
            "Epoch 402/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4339 - mean_absolute_error: 8.0602 - val_loss: 7.9423 - val_mean_absolute_error: 8.5889\n",
            "Epoch 403/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4383 - mean_absolute_error: 8.0645 - val_loss: 8.0056 - val_mean_absolute_error: 8.6481\n",
            "Epoch 404/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.5003 - mean_absolute_error: 8.1271 - val_loss: 8.3572 - val_mean_absolute_error: 9.0124\n",
            "Epoch 405/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4364 - mean_absolute_error: 8.0634 - val_loss: 8.0676 - val_mean_absolute_error: 8.7195\n",
            "Epoch 406/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4622 - mean_absolute_error: 8.0892 - val_loss: 7.7088 - val_mean_absolute_error: 8.3370\n",
            "Epoch 407/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4450 - mean_absolute_error: 8.0713 - val_loss: 8.1639 - val_mean_absolute_error: 8.8175\n",
            "Epoch 408/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4948 - mean_absolute_error: 8.1223 - val_loss: 7.8748 - val_mean_absolute_error: 8.5215\n",
            "Epoch 409/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4708 - mean_absolute_error: 8.0985 - val_loss: 7.9764 - val_mean_absolute_error: 8.6262\n",
            "Epoch 410/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4677 - mean_absolute_error: 8.0940 - val_loss: 8.1809 - val_mean_absolute_error: 8.8292\n",
            "Epoch 411/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4718 - mean_absolute_error: 8.0984 - val_loss: 7.9811 - val_mean_absolute_error: 8.6254\n",
            "Epoch 412/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4343 - mean_absolute_error: 8.0613 - val_loss: 8.1055 - val_mean_absolute_error: 8.7467\n",
            "Epoch 413/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4173 - mean_absolute_error: 8.0433 - val_loss: 7.9146 - val_mean_absolute_error: 8.5541\n",
            "Epoch 414/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4724 - mean_absolute_error: 8.0989 - val_loss: 7.6566 - val_mean_absolute_error: 8.2756\n",
            "Epoch 415/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4438 - mean_absolute_error: 8.0708 - val_loss: 7.9800 - val_mean_absolute_error: 8.6190\n",
            "Epoch 416/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4569 - mean_absolute_error: 8.0832 - val_loss: 8.3502 - val_mean_absolute_error: 9.0019\n",
            "Epoch 417/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4405 - mean_absolute_error: 8.0670 - val_loss: 8.0657 - val_mean_absolute_error: 8.7104\n",
            "Epoch 418/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4617 - mean_absolute_error: 8.0886 - val_loss: 8.2908 - val_mean_absolute_error: 8.9467\n",
            "Epoch 419/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4611 - mean_absolute_error: 8.0878 - val_loss: 7.7237 - val_mean_absolute_error: 8.3289\n",
            "Epoch 420/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4534 - mean_absolute_error: 8.0794 - val_loss: 8.0915 - val_mean_absolute_error: 8.7421\n",
            "Epoch 421/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4425 - mean_absolute_error: 8.0694 - val_loss: 8.1401 - val_mean_absolute_error: 8.7920\n",
            "Epoch 422/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4820 - mean_absolute_error: 8.1090 - val_loss: 7.7323 - val_mean_absolute_error: 8.3504\n",
            "Epoch 423/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4653 - mean_absolute_error: 8.0910 - val_loss: 7.9986 - val_mean_absolute_error: 8.6421\n",
            "Epoch 424/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4102 - mean_absolute_error: 8.0360 - val_loss: 8.0116 - val_mean_absolute_error: 8.6551\n",
            "Epoch 425/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.4676 - mean_absolute_error: 8.0948 - val_loss: 8.4070 - val_mean_absolute_error: 9.0644\n",
            "Epoch 426/500\n",
            "178160/178160 [==============================] - 11s 65us/step - loss: 7.4235 - mean_absolute_error: 8.0504 - val_loss: 8.2321 - val_mean_absolute_error: 8.8801\n",
            "Epoch 427/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4844 - mean_absolute_error: 8.1115 - val_loss: 8.0055 - val_mean_absolute_error: 8.6416\n",
            "Epoch 428/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4115 - mean_absolute_error: 8.0372 - val_loss: 7.7065 - val_mean_absolute_error: 8.3409\n",
            "Epoch 429/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4113 - mean_absolute_error: 8.0377 - val_loss: 7.9240 - val_mean_absolute_error: 8.5704\n",
            "Epoch 430/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4590 - mean_absolute_error: 8.0853 - val_loss: 7.8678 - val_mean_absolute_error: 8.5159\n",
            "Epoch 431/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4500 - mean_absolute_error: 8.0771 - val_loss: 8.0517 - val_mean_absolute_error: 8.6964\n",
            "Epoch 432/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4535 - mean_absolute_error: 8.0800 - val_loss: 7.9205 - val_mean_absolute_error: 8.5631\n",
            "Epoch 433/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4674 - mean_absolute_error: 8.0945 - val_loss: 8.1341 - val_mean_absolute_error: 8.7786\n",
            "Epoch 434/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4157 - mean_absolute_error: 8.0415 - val_loss: 7.9749 - val_mean_absolute_error: 8.6192\n",
            "Epoch 435/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4335 - mean_absolute_error: 8.0602 - val_loss: 7.8028 - val_mean_absolute_error: 8.4252\n",
            "Epoch 436/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4310 - mean_absolute_error: 8.0579 - val_loss: 7.9728 - val_mean_absolute_error: 8.6219\n",
            "Epoch 437/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4677 - mean_absolute_error: 8.0954 - val_loss: 8.0136 - val_mean_absolute_error: 8.6634\n",
            "Epoch 438/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4420 - mean_absolute_error: 8.0684 - val_loss: 8.4576 - val_mean_absolute_error: 9.1115\n",
            "Epoch 439/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4431 - mean_absolute_error: 8.0694 - val_loss: 8.1655 - val_mean_absolute_error: 8.8178\n",
            "Epoch 440/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4358 - mean_absolute_error: 8.0630 - val_loss: 8.0388 - val_mean_absolute_error: 8.6860\n",
            "Epoch 441/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4866 - mean_absolute_error: 8.1126 - val_loss: 8.9792 - val_mean_absolute_error: 9.6443\n",
            "Epoch 442/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.4607 - mean_absolute_error: 8.0876 - val_loss: 8.2493 - val_mean_absolute_error: 8.9034\n",
            "Epoch 443/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4523 - mean_absolute_error: 8.0781 - val_loss: 7.8131 - val_mean_absolute_error: 8.4295\n",
            "Epoch 444/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4400 - mean_absolute_error: 8.0659 - val_loss: 8.6197 - val_mean_absolute_error: 9.2677\n",
            "Epoch 445/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4529 - mean_absolute_error: 8.0796 - val_loss: 8.3875 - val_mean_absolute_error: 9.0311\n",
            "Epoch 446/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4190 - mean_absolute_error: 8.0454 - val_loss: 8.0011 - val_mean_absolute_error: 8.6449\n",
            "Epoch 447/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4333 - mean_absolute_error: 8.0588 - val_loss: 8.1461 - val_mean_absolute_error: 8.7991\n",
            "Epoch 448/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4490 - mean_absolute_error: 8.0762 - val_loss: 8.0201 - val_mean_absolute_error: 8.6633\n",
            "Epoch 449/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3935 - mean_absolute_error: 8.0189 - val_loss: 8.1050 - val_mean_absolute_error: 8.7505\n",
            "Epoch 450/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4562 - mean_absolute_error: 8.0825 - val_loss: 8.2369 - val_mean_absolute_error: 8.8910\n",
            "Epoch 451/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4365 - mean_absolute_error: 8.0627 - val_loss: 7.9104 - val_mean_absolute_error: 8.5604\n",
            "Epoch 452/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.4616 - mean_absolute_error: 8.0878 - val_loss: 8.5595 - val_mean_absolute_error: 9.2177\n",
            "Epoch 453/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4323 - mean_absolute_error: 8.0588 - val_loss: 8.3239 - val_mean_absolute_error: 8.9699\n",
            "Epoch 454/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4091 - mean_absolute_error: 8.0348 - val_loss: 7.9382 - val_mean_absolute_error: 8.5647\n",
            "Epoch 455/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4120 - mean_absolute_error: 8.0380 - val_loss: 8.1331 - val_mean_absolute_error: 8.7819\n",
            "Epoch 456/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4046 - mean_absolute_error: 8.0308 - val_loss: 8.5044 - val_mean_absolute_error: 9.1570\n",
            "Epoch 457/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4385 - mean_absolute_error: 8.0645 - val_loss: 7.9534 - val_mean_absolute_error: 8.6008\n",
            "Epoch 458/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3992 - mean_absolute_error: 8.0248 - val_loss: 7.8668 - val_mean_absolute_error: 8.5020\n",
            "Epoch 459/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3656 - mean_absolute_error: 7.9914 - val_loss: 8.1825 - val_mean_absolute_error: 8.8343\n",
            "Epoch 460/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4454 - mean_absolute_error: 8.0718 - val_loss: 7.9991 - val_mean_absolute_error: 8.6362\n",
            "Epoch 461/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4507 - mean_absolute_error: 8.0776 - val_loss: 8.3556 - val_mean_absolute_error: 9.0017\n",
            "Epoch 462/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4054 - mean_absolute_error: 8.0308 - val_loss: 8.1443 - val_mean_absolute_error: 8.7920\n",
            "Epoch 463/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3789 - mean_absolute_error: 8.0042 - val_loss: 7.9415 - val_mean_absolute_error: 8.5893\n",
            "Epoch 464/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4277 - mean_absolute_error: 8.0533 - val_loss: 8.0637 - val_mean_absolute_error: 8.7099\n",
            "Epoch 465/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4033 - mean_absolute_error: 8.0289 - val_loss: 7.8522 - val_mean_absolute_error: 8.4956\n",
            "Epoch 466/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4146 - mean_absolute_error: 8.0399 - val_loss: 8.1439 - val_mean_absolute_error: 8.7971\n",
            "Epoch 467/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4407 - mean_absolute_error: 8.0666 - val_loss: 7.9513 - val_mean_absolute_error: 8.5976\n",
            "Epoch 468/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4394 - mean_absolute_error: 8.0656 - val_loss: 9.3775 - val_mean_absolute_error: 10.0428\n",
            "Epoch 469/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3968 - mean_absolute_error: 8.0230 - val_loss: 7.9103 - val_mean_absolute_error: 8.5590\n",
            "Epoch 470/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4107 - mean_absolute_error: 8.0354 - val_loss: 8.3201 - val_mean_absolute_error: 8.9759\n",
            "Epoch 471/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4252 - mean_absolute_error: 8.0519 - val_loss: 7.9758 - val_mean_absolute_error: 8.6100\n",
            "Epoch 472/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4311 - mean_absolute_error: 8.0572 - val_loss: 8.0017 - val_mean_absolute_error: 8.6515\n",
            "Epoch 473/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3997 - mean_absolute_error: 8.0258 - val_loss: 8.0572 - val_mean_absolute_error: 8.7033\n",
            "Epoch 474/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4259 - mean_absolute_error: 8.0517 - val_loss: 8.1644 - val_mean_absolute_error: 8.8106\n",
            "Epoch 475/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4151 - mean_absolute_error: 8.0422 - val_loss: 8.0039 - val_mean_absolute_error: 8.6504\n",
            "Epoch 476/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4092 - mean_absolute_error: 8.0351 - val_loss: 7.8726 - val_mean_absolute_error: 8.5153\n",
            "Epoch 477/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4391 - mean_absolute_error: 8.0651 - val_loss: 7.9630 - val_mean_absolute_error: 8.6152\n",
            "Epoch 478/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3908 - mean_absolute_error: 8.0162 - val_loss: 7.7514 - val_mean_absolute_error: 8.3830\n",
            "Epoch 479/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3968 - mean_absolute_error: 8.0222 - val_loss: 8.3688 - val_mean_absolute_error: 9.0270\n",
            "Epoch 480/500\n",
            "178160/178160 [==============================] - 12s 65us/step - loss: 7.4184 - mean_absolute_error: 8.0443 - val_loss: 7.9544 - val_mean_absolute_error: 8.5993\n",
            "Epoch 481/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3829 - mean_absolute_error: 8.0088 - val_loss: 7.9113 - val_mean_absolute_error: 8.5574\n",
            "Epoch 482/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4067 - mean_absolute_error: 8.0322 - val_loss: 8.2379 - val_mean_absolute_error: 8.8882\n",
            "Epoch 483/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3990 - mean_absolute_error: 8.0246 - val_loss: 7.9785 - val_mean_absolute_error: 8.6308\n",
            "Epoch 484/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4059 - mean_absolute_error: 8.0317 - val_loss: 8.1808 - val_mean_absolute_error: 8.8238\n",
            "Epoch 485/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4324 - mean_absolute_error: 8.0585 - val_loss: 8.1670 - val_mean_absolute_error: 8.8190\n",
            "Epoch 486/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4098 - mean_absolute_error: 8.0353 - val_loss: 8.3283 - val_mean_absolute_error: 8.9855\n",
            "Epoch 487/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4102 - mean_absolute_error: 8.0351 - val_loss: 8.0267 - val_mean_absolute_error: 8.6776\n",
            "Epoch 488/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4277 - mean_absolute_error: 8.0538 - val_loss: 7.9446 - val_mean_absolute_error: 8.5941\n",
            "Epoch 489/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4117 - mean_absolute_error: 8.0371 - val_loss: 8.0457 - val_mean_absolute_error: 8.6970\n",
            "Epoch 490/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4243 - mean_absolute_error: 8.0493 - val_loss: 7.8925 - val_mean_absolute_error: 8.5186\n",
            "Epoch 491/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4193 - mean_absolute_error: 8.0451 - val_loss: 8.1402 - val_mean_absolute_error: 8.7843\n",
            "Epoch 492/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3958 - mean_absolute_error: 8.0212 - val_loss: 8.7032 - val_mean_absolute_error: 9.3611\n",
            "Epoch 493/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4083 - mean_absolute_error: 8.0334 - val_loss: 7.8697 - val_mean_absolute_error: 8.5154\n",
            "Epoch 494/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4451 - mean_absolute_error: 8.0704 - val_loss: 7.9541 - val_mean_absolute_error: 8.6023\n",
            "Epoch 495/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4120 - mean_absolute_error: 8.0376 - val_loss: 8.2074 - val_mean_absolute_error: 8.8622\n",
            "Epoch 496/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3941 - mean_absolute_error: 8.0191 - val_loss: 7.9629 - val_mean_absolute_error: 8.6093\n",
            "Epoch 497/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4309 - mean_absolute_error: 8.0569 - val_loss: 7.7282 - val_mean_absolute_error: 8.3591\n",
            "Epoch 498/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4275 - mean_absolute_error: 8.0526 - val_loss: 7.6901 - val_mean_absolute_error: 8.3222\n",
            "Epoch 499/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.4634 - mean_absolute_error: 8.0888 - val_loss: 7.8858 - val_mean_absolute_error: 8.5303\n",
            "Epoch 500/500\n",
            "178160/178160 [==============================] - 11s 64us/step - loss: 7.3846 - mean_absolute_error: 8.0100 - val_loss: 7.9339 - val_mean_absolute_error: 8.5830\n",
            "Train MAE =  7.991426530203372\n",
            "Train MAPE =  [0.13469523]\n",
            "Test MAE =  8.275624722242355\n",
            "Test MAPE =  [0.13612635]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqI49/+0JRar/iJuMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}